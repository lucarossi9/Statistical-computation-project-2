# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RMzJz-n9UYMKEuzEFU3qtZm0TJzVU7ue
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive 
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/Colab\ Notebooks

!pip install "dask[dataframe]"
!pip install "dask[bag]"
!pip install "dask[array]"

import numpy as np
import pandas as pd
import json
import dask.bag as db
import dask.dataframe as dd # substitute of pandas to load the data in streams
import dask.array as da

dict_bag = db.read_text('yelp_academic_dataset_review.json', blocksize=int(5e6)).map(json.loads)
df_r = dict_bag.to_dataframe(columns=['text', 'stars'])
df_r = df_r.repartition(npartitions=10)

df_r.head()

df_r = df_r.compute()

!pip install nltk

import nltk
import string
nltk.download("stopwords")

from nltk.corpus import stopwords
sw_nltk = stopwords.words('english')
print(sw_nltk)

#n = len(df_r['text'])
df = df_r.sample(10000)
nt = []
for i in range(10000):
  s = str(df['text'].values[i])
  words = [word for word in s.split() if word.lower() not in sw_nltk]
  new_text = " ".join(words)
  new_text = new_text.translate(str.maketrans('', '', string.punctuation))
  nt.append(new_text.lower()) 
df['new_text'] = nt

df

!pip install gensim

import gensim

from gensim.utils import simple_preprocess
import gensim.corpora as corpora

def sent_to_words(sentences):
    for sentence in sentences:
        # deacc=True removes punctuations
        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))

data = df.new_text.values.tolist()
data_words = list(sent_to_words(data))

id2word = corpora.Dictionary(data_words)

texts = data_words
corpus = [id2word.doc2bow(text) for text in texts]


